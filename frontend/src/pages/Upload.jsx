import React, { useState, useRef, useEffect } from 'react';
import { Upload as UploadIcon, Camera, RefreshCw, Check, AlertTriangle, Brain, Zap, Globe } from 'lucide-react';
import { wildlifeTensorFlowService } from '../services/wildlifeTensorFlowClean.js';

const Upload = () => {
  const [selectedFile, setSelectedFile] = useState(null);
  const [previewUrl, setPreviewUrl] = useState(null);
  const [uploadResult, setUploadResult] = useState(null);
  const [tensorFlowResult, setTensorFlowResult] = useState(null);
  const [isProcessing, setIsProcessing] = useState(false);
  const [modelInfo, setModelInfo] = useState(null);
  const [downloadProgress, setDownloadProgress] = useState({});
  const [systemReady, setSystemReady] = useState(false);
  const fileInputRef = useRef(null);
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const [stream, setStream] = useState(null);
  const [detectionHistory, setDetectionHistory] = useState([]);
  const [isMonitoring, setIsMonitoring] = useState(false);

  // Initialize TensorFlow service
  useEffect(() => {
    const initializeSystem = async () => {
      try {
        console.log("üöÄ [Upload Component] Starting system initialization...");
        setSystemReady(false); // Ensure we start in loading state
        
        // Initialize with progress tracking
        console.log("üì• [Upload Component] Starting model downloads...");
        await wildlifeTensorFlowService.initialize((progress) => {
          console.log("üìä [Upload Component] Download progress update:", Object.keys(progress).length, "models");
          setDownloadProgress(progress);
        });
        
        console.log("üìà [Upload Component] Getting model statistics...");
        // Get model information
        const stats = wildlifeTensorFlowService.getModelStats();
        setModelInfo(stats);
        
        console.log("‚úÖ [Upload Component] Setting system ready = TRUE");
        console.log("üéØ [Upload Component] Models loaded:", stats.pretrainedModelsCount);
        console.log("üåç [Upload Component] Species count:", stats.speciesCount);
        
        setSystemReady(true);
        
        console.log("üéâ [Upload Component] Enterprise system FULLY READY for wildlife detection!");
        
      } catch (error) {
        console.error("‚ùå [Upload Component] System initialization failed:", error);
        setSystemReady(false);
      }
    };

    initializeSystem();
  }, []);

  // Continuous monitoring with improved error handling
  useEffect(() => {
    let interval;
    
    if (isMonitoring && stream && systemReady) {
      console.log("üîÑ Starting continuous monitoring...");
      interval = setInterval(async () => {
        try {
          await captureAndAnalyze();
        } catch (error) {
          console.warn("‚ö†Ô∏è Monitoring frame analysis failed:", error);
        }
      }, 3000); // Analyze every 3 seconds for better performance
    } else {
      console.log("‚è∏Ô∏è Monitoring paused:", { isMonitoring, hasStream: !!stream, systemReady });
    }
    
    return () => {
      if (interval) {
        console.log("üõë Stopping monitoring interval");
        clearInterval(interval);
      }
    };
  }, [isMonitoring, stream, systemReady]);

  const handleFileSelect = (event) => {
    const file = event.target.files[0];
    if (file) {
      setSelectedFile(file);
      const url = URL.createObjectURL(file);
      setPreviewUrl(url);
      
      // Auto-analyze with TensorFlow
      if (systemReady) {
        analyzeTensorFlow(file);
      }
    }
  };

  const handleUpload = async () => {
    if (!selectedFile) return;

    setUploadResult({ status: 'uploading' });

    try {
      console.log("üì§ Starting both web analysis and server upload...");
      
      // First, do local web-based analysis
      setUploadResult({ status: 'processing', message: 'Analyzing locally...' });
      await analyzeTensorFlow(selectedFile);
      
      // Then, also upload to server for server-side processing
      console.log("üì§ Uploading to server for server-side analysis...");
      setUploadResult({ status: 'processing', message: 'Uploading to server...' });
      
      const formData = new FormData();
      formData.append('image', selectedFile);
      formData.append('metadata', JSON.stringify({
        source: 'upload',
        tensorFlowResult: tensorFlowResult
      }));

      try {
        // First get a test token for authentication
        const tokenResponse = await fetch('http://localhost:5001/api/test/login', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            email: 'test@example.com',
            password: 'test123'
          })
        });
        
        let authHeaders = {};
        if (tokenResponse.ok) {
          const tokenResult = await tokenResponse.json();
          authHeaders = {
            'Authorization': `Bearer ${tokenResult.data.token}`
          };
        }

        // Send detection to MongoDB backend for storage
        const detectionData = new FormData();
        detectionData.append('image', selectedFile);
        detectionData.append('species', result.species);
        detectionData.append('confidence', result.confidence);
        detectionData.append('longitude', -122.4194); // Default coordinates (San Francisco)
        detectionData.append('latitude', 37.7749);
        detectionData.append('country', 'United States');
        detectionData.append('region', 'California');
        detectionData.append('continent', 'North America');
        detectionData.append('habitat', 'Urban');
        detectionData.append('notes', `Detected via web upload with ${(result.confidence * 100).toFixed(1)}% confidence`);

        const response = await fetch('http://localhost:5001/api/wildlife/detect', {
          method: 'POST',
          headers: authHeaders,
          body: detectionData,
        });

        if (response.ok) {
          const serverResult = await response.json();
          console.log("‚úÖ Wildlife detection stored in MongoDB:", serverResult);
          
          setUploadResult({ 
            status: 'completed', 
            result: {
              message: "Wildlife detection completed and stored in database",
              timestamp: new Date().toISOString(),
              filename: selectedFile.name,
              size: selectedFile.size,
              type: selectedFile.type,
              species: result.species,
              confidence: result.confidence,
              detectionId: serverResult.detection?.id,
              conservationAlert: serverResult.detection?.conservationAlert,
              mongoStorage: true,
              webAnalysis: "Completed with TensorFlow.js",
              serverStorage: "Stored in MongoDB"
            }
          });
        } else {
          const errorData = await response.json().catch(() => ({ message: 'Unknown server error' }));
          throw new Error(`Server storage failed: ${errorData.message}`);
        }
        
      } catch (serverError) {
        console.warn("‚ö†Ô∏è Server upload failed, using web-only analysis:", serverError.message);
        
        // Fall back to web-only processing
        setUploadResult({ 
          status: 'completed', 
          result: {
            message: "Image processed successfully with web-based analysis (server unavailable)",
            timestamp: new Date().toISOString(),
            filename: selectedFile.name,
            size: selectedFile.size,
            type: selectedFile.type,
            webAnalysis: "Completed locally",
            serverAnalysis: "Server unavailable",
            fallbackMode: true
          }
        });
      }
      
      console.log("‚úÖ Upload and analysis completed");
      
    } catch (error) {
      console.error("‚ùå Upload/analysis failed:", error);
      setUploadResult({ 
        status: 'error', 
        error: error.message 
      });
    }
  };

  const analyzeTensorFlow = async (file) => {
    if (!systemReady) {
      console.warn("System not ready for analysis");
      return;
    }

    setIsProcessing(true);
    setTensorFlowResult(null);

    try {
      const img = new Image();
      img.onload = async () => {
        try {
          // Use the advanced enterprise detection pipeline
          const result = await wildlifeTensorFlowService.analyzeFrame(img);
          
          setTensorFlowResult(result);
          
          if (result.isWildlife) {
            addToDetectionHistory(result);
          }
          
        } catch (error) {
          console.error("TensorFlow analysis error:", error);
          setTensorFlowResult({
            error: error.message,
            isWildlife: false,
            confidence: 0
          });
        } finally {
          setIsProcessing(false);
        }
      };
      
      img.src = URL.createObjectURL(file);
      
    } catch (error) {
      console.error("Image processing error:", error);
      setTensorFlowResult({
        error: "Failed to process image",
        isWildlife: false,
        confidence: 0
      });
      setIsProcessing(false);
    }
  };

  const addToDetectionHistory = (result) => {
    const detection = {
      ...result,
      timestamp: new Date().toLocaleTimeString(),
      id: Date.now()
    };
    
    setDetectionHistory(prev => [detection, ...prev.slice(0, 9)]); // Keep last 10
  };

  const startCamera = async () => {
    try {
      console.log("üìπ Starting camera...");
      
      // Check if video element is available
      if (!videoRef.current) {
        console.error("‚ùå Video element not available");
        throw new Error("Video element not found. Please try again.");
      }
      
      // Check for camera support
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error("Camera access not supported in this browser");
      }
      
      // Enhanced camera constraints for better video display
      const constraints = {
        video: { 
          width: { ideal: 1280, min: 640 }, 
          height: { ideal: 720, min: 480 },
          facingMode: 'environment', // Use back camera if available
          frameRate: { ideal: 30, min: 15 }
        },
        audio: false
      };
      
      console.log("üé• Requesting camera permissions...");
      const mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
      
      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream;
        
        // Enhanced video setup for better display with Promise-based loading
        await new Promise((resolve, reject) => {
          const timeoutId = setTimeout(() => {
            reject(new Error("Video loading timeout"));
          }, 10000);
          
          videoRef.current.onloadedmetadata = () => {
            clearTimeout(timeoutId);
            console.log("üìπ Video metadata loaded:", {
              width: videoRef.current.videoWidth,
              height: videoRef.current.videoHeight,
              readyState: videoRef.current.readyState
            });
            resolve();
          };
          
          videoRef.current.onerror = (error) => {
            clearTimeout(timeoutId);
            reject(new Error(`Video loading error: ${error.message}`));
          };
        });
        
        // Ensure video plays
        try {
          await videoRef.current.play();
          console.log("‚úÖ Video is playing successfully");
        } catch (playError) {
          console.warn("‚ö†Ô∏è Video autoplay blocked, user interaction required:", playError);
          // Video will play when user interacts
        }
        
        setStream(mediaStream);
        console.log("‚úÖ Camera started successfully with enhanced display");
        console.log("üìä Stream tracks:", mediaStream.getTracks().map(t => ({ 
          kind: t.kind, 
          enabled: t.enabled, 
          readyState: t.readyState,
          label: t.label 
        })));
      }
    } catch (error) {
      console.error('‚ùå Camera access failed:', error);
      alert(`Camera access failed: ${error.message}. Please ensure you have granted camera permissions and refresh the page.`);
    }
  };

  const stopCamera = () => {
    if (stream) {
      stream.getTracks().forEach(track => {
        console.log(`üõë Stopping ${track.kind} track`);
        track.stop();
      });
      setStream(null);
      
      // Clear video element
      if (videoRef.current) {
        videoRef.current.srcObject = null;
      }
      
      console.log("üõë Camera stopped and cleaned up");
    }
    setIsMonitoring(false);
  };

  // Test video display functionality
  const testVideoDisplay = () => {
    if (videoRef.current && stream) {
      const video = videoRef.current;
      console.log("üîç Video Display Test:", {
        hasStream: !!stream,
        videoElement: !!video,
        srcObject: !!video.srcObject,
        readyState: video.readyState,
        paused: video.paused,
        muted: video.muted,
        autoplay: video.autoplay,
        dimensions: `${video.videoWidth}x${video.videoHeight}`,
        style: video.style.display
      });
      
      // Force play if needed
      if (video.paused) {
        video.play().then(() => {
          console.log("‚úÖ Video playing after test");
        }).catch(e => {
          console.error("‚ùå Video play failed in test:", e);
        });
      }
    }
  };

  const captureAndAnalyze = async () => {
    if (!videoRef.current || !canvasRef.current || !systemReady) {
      console.warn("‚ö†Ô∏è Cannot capture: missing video, canvas, or system not ready");
      return;
    }

    const canvas = canvasRef.current;
    const video = videoRef.current;
    const ctx = canvas.getContext('2d');
    
    // Ensure video is playing
    if (video.readyState < 2) {
      console.warn("‚ö†Ô∏è Video not ready for capture");
      return;
    }
    
    console.log("üì∏ Capturing frame for analysis...");
    
    canvas.width = video.videoWidth || 640;
    canvas.height = video.videoHeight || 480;
    ctx.drawImage(video, 0, 0);
    
    try {
      // Convert canvas to blob and create image for analysis
      canvas.toBlob(async (blob) => {
        if (!blob) {
          console.warn("‚ö†Ô∏è Failed to create blob from canvas");
          return;
        }
        
        try {
          console.log("üîç Analyzing captured frame...");
          const result = await wildlifeTensorFlowService.analyzeImage(blob);
          
          console.log("üìä Real-time analysis result:", result);
          setTensorFlowResult(result);
          
          if (result.isWildlife && result.confidence > 0.3) {
            addToDetectionHistory(result);
            console.log("‚úÖ Wildlife detected and added to history");
            
            // Store detection in MongoDB backend
            try {
              console.log("üíæ Storing live detection in MongoDB...");
              
              // Get auth token
              let authHeaders = { 'Content-Type': 'application/json' };
              const tokenResult = await apiCall('/auth/token');
              if (tokenResult.success) {
                authHeaders['Authorization'] = `Bearer ${tokenResult.data.token}`;
              }
              
              // Convert blob to FormData
              const formData = new FormData();
              formData.append('image', blob, `live-detection-${Date.now()}.jpg`);
              formData.append('species', result.species);
              formData.append('confidence', result.confidence);
              formData.append('longitude', -122.4194); // Default coordinates
              formData.append('latitude', 37.7749);
              formData.append('country', 'United States');
              formData.append('region', 'California');
              formData.append('continent', 'North America');
              formData.append('habitat', 'Live Camera Feed');
              formData.append('notes', `Live detection via camera feed with ${(result.confidence * 100).toFixed(1)}% confidence`);
              
              // Remove Content-Type for FormData
              delete authHeaders['Content-Type'];
              
              const storeResponse = await fetch('http://localhost:5001/api/wildlife/detect', {
                method: 'POST',
                headers: authHeaders,
                body: formData
              });
              
              if (storeResponse.ok) {
                const storeResult = await storeResponse.json();
                console.log("‚úÖ Live detection stored in MongoDB:", storeResult);
                
                // Update result with storage info
                setTensorFlowResult({
                  ...result,
                  mongoStored: true,
                  detectionId: storeResult.detection?.id,
                  conservationAlert: storeResult.detection?.conservationAlert
                });
              } else {
                console.warn("‚ö†Ô∏è Failed to store live detection:", await storeResponse.text());
              }
            } catch (storageError) {
              console.error("‚ùå Error storing live detection:", storageError);
            }
          }
        } catch (analysisError) {
          console.error("‚ùå Real-time analysis error:", analysisError);
        }
      }, 'image/jpeg', 0.8);
      
    } catch (error) {
      console.warn("‚ö†Ô∏è Real-time analysis error:", error);
    }
  };

  const renderSystemStatus = () => (
    <div className="mb-6 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-4">
      <div className="flex items-center justify-between mb-3">
        <h3 className="font-bold text-blue-900 flex items-center">
          <Brain className="w-5 h-5 mr-2" />
          Enterprise Wildlife Detection System
        </h3>
        <div className={`px-3 py-1 rounded-full text-xs font-medium ${
          systemReady ? 'bg-green-100 text-green-800' : 'bg-yellow-100 text-yellow-800'
        }`}>
          {systemReady ? '‚úÖ READY' : '‚è≥ LOADING'}
        </div>
      </div>
      
      {modelInfo && (
        <div className="grid grid-cols-1 md:grid-cols-3 gap-4 text-xs">
          <div className="bg-white rounded p-3 border">
            <div className="font-medium text-gray-900 mb-1">ü§ñ Models Loaded</div>
            <div className="text-blue-600 font-bold">{modelInfo.pretrainedModelsCount}/6</div>
            <div className="text-gray-500">Pre-trained architectures</div>
          </div>
          <div className="bg-white rounded p-3 border">
            <div className="font-medium text-gray-900 mb-1">üåç Species Database</div>
            <div className="text-green-600 font-bold">{modelInfo.speciesCount}</div>
            <div className="text-gray-500">Global wildlife species</div>
          </div>
          <div className="bg-white rounded p-3 border">
            <div className="font-medium text-gray-900 mb-1">üéØ Accuracy Range</div>
            <div className="text-purple-600 font-bold">89.3% - 97.8%</div>
            <div className="text-gray-500">Enterprise grade</div>
          </div>
        </div>
      )}
      
      {Object.keys(downloadProgress).length > 0 && (
        <div className="mt-3 space-y-3">
          <div className="text-sm font-medium text-blue-900 flex items-center">
            üöÄ Downloading Enterprise Models:
            <span className="ml-2 text-xs bg-blue-100 text-blue-800 px-2 py-1 rounded">
              {Object.values(downloadProgress).filter(p => p.status === 'completed').length}/{Object.keys(downloadProgress).length} Complete
            </span>
          </div>
          {Object.entries(downloadProgress).map(([modelName, progress]) => (
            <div key={modelName} className="bg-white rounded-lg p-3 border border-blue-200">
              <div className="flex items-center justify-between mb-2">
                <div className="flex items-center">
                  <span className="font-medium text-blue-800">{modelName}</span>
                  <span className="ml-2 text-xs bg-gray-100 text-gray-600 px-2 py-1 rounded">
                    {progress.size || 'Unknown size'}
                  </span>
                  {progress.accuracy && (
                    <span className="ml-1 text-xs bg-green-100 text-green-600 px-2 py-1 rounded">
                      {progress.accuracy}
                    </span>
                  )}
                </div>
                <div className="flex items-center">
                  {progress.status === 'completed' && (
                    <Check className="w-4 h-4 text-green-600 mr-1" />
                  )}
                  {progress.status === 'downloading' && (
                    <RefreshCw className="w-4 h-4 text-blue-600 mr-1 animate-spin" />
                  )}
                  <span className="text-sm font-medium text-blue-600">{progress.percentage || 0}%</span>
                </div>
              </div>
              <div className="flex items-center">
                <div className="flex-1 bg-blue-100 rounded-full h-3 mr-2">
                  <div 
                    className={`h-3 rounded-full transition-all duration-300 ${
                      progress.status === 'completed' ? 'bg-green-500' : 'bg-blue-500'
                    }`}
                    style={{ width: `${progress.percentage || 0}%` }}
                  ></div>
                </div>
                {progress.current && progress.total && (
                  <span className="text-xs text-gray-600">
                    {Math.round(progress.current / 1024)}KB / {Math.round(progress.total / 1024)}KB
                  </span>
                )}
              </div>
              <div className="mt-1 text-xs text-gray-500 capitalize">
                Status: {progress.status || 'pending'}
              </div>
            </div>
          ))}
        </div>
      )}
    </div>
  );

  const renderTensorFlowResults = () => {
    if (!tensorFlowResult && !isProcessing) return null;

    return (
      <div className="mt-8 border border-blue-200 rounded-lg p-6 bg-blue-50">
        <h3 className="text-lg font-medium text-blue-900 mb-4 flex items-center">
          üß† Enterprise AI Analysis
          <span className="ml-2 text-xs bg-blue-200 text-blue-800 px-2 py-1 rounded">
            Three-Stage Pipeline
          </span>
        </h3>
        
        {isProcessing && (
          <div className="flex items-center text-blue-600 mb-4">
            <RefreshCw className="w-4 h-4 mr-2 animate-spin" />
            Advanced TensorFlow.js pipeline analyzing...
          </div>
        )}

        {tensorFlowResult && !tensorFlowResult.error && (
          <div className="bg-gradient-to-r from-emerald-50 to-green-50 rounded-lg p-4 border border-emerald-200 mb-4">
            <div className="flex items-center justify-between mb-3">
              <h4 className="font-bold text-emerald-900">üéØ Detection Result</h4>
              <div className="text-xs text-emerald-700 bg-emerald-100 px-2 py-1 rounded">
                {tensorFlowResult.model} ‚Ä¢ {tensorFlowResult.accuracy}
              </div>
            </div>
            
            <div className="space-y-2 text-sm">
              <div className="flex items-center justify-between">
                <span className="font-medium text-emerald-900">Species:</span> 
                <span className="font-bold text-emerald-800">{tensorFlowResult.species}</span>
              </div>
              
              {tensorFlowResult.scientificName && (
                <div className="flex items-center justify-between">
                  <span className="font-medium text-emerald-900">Scientific Name:</span>
                  <span className="italic text-emerald-700">{tensorFlowResult.scientificName}</span>
                </div>
              )}
              
              <div className="flex items-center justify-between">
                <span className="font-medium text-emerald-900">Confidence:</span>
                <div className="flex items-center">
                  <div className="w-20 bg-emerald-200 rounded-full h-2 mr-2">
                    <div 
                      className="bg-emerald-600 h-2 rounded-full" 
                      style={{ width: `${(tensorFlowResult.confidence * 100)}%` }}
                    ></div>
                  </div>
                  <span className="font-bold text-emerald-800">
                    {(tensorFlowResult.confidence * 100).toFixed(1)}%
                  </span>
                </div>
              </div>
              
              {tensorFlowResult.habitat && (
                <div className="flex items-center justify-between">
                  <span className="font-medium text-emerald-900">Habitat:</span>
                  <span className="text-emerald-700">{tensorFlowResult.habitat}</span>
                </div>
              )}
              
              {tensorFlowResult.conservationStatus && (
                <div className="flex items-center justify-between">
                  <span className="font-medium text-emerald-900">Conservation:</span>
                  <span className={`px-2 py-1 rounded text-xs font-medium ${
                    tensorFlowResult.conservationStatus.includes('Endangered') ? 'bg-red-100 text-red-800' :
                    tensorFlowResult.conservationStatus.includes('Vulnerable') ? 'bg-yellow-100 text-yellow-800' :
                    'bg-green-100 text-green-800'
                  }`}>
                    {tensorFlowResult.conservationStatus}
                  </span>
                </div>
              )}
              
              <div className="pt-2 border-t border-emerald-200">
                <div className="flex items-center justify-between text-xs">
                  <span className="text-emerald-700">Pipeline Stage:</span>
                  <span className="font-medium text-emerald-800">{tensorFlowResult.stage}</span>
                </div>
                {tensorFlowResult.boundingBox && (
                  <div className="flex items-center justify-between text-xs mt-1">
                    <span className="text-emerald-700">Object Detection:</span>
                    <span className="font-medium text-emerald-800">‚úì Located</span>
                  </div>
                )}
                {tensorFlowResult.faceDetection && (
                  <div className="flex items-center justify-between text-xs mt-1">
                    <span className="text-emerald-700">Face Detection:</span>
                    <span className="font-medium text-emerald-800">
                      {tensorFlowResult.faceDetection.detected ? '‚úì Detected' : '‚úó None'}
                    </span>
                  </div>
                )}
              </div>
              
              <div className="bg-emerald-100 rounded p-2 mt-3">
                <p className="text-emerald-800 text-xs font-medium">
                  üí¨ {tensorFlowResult.message}
                </p>
              </div>
            </div>
          </div>
        )}

        {tensorFlowResult && tensorFlowResult.error && (
          <div className="bg-red-50 border border-red-200 rounded-lg p-4">
            <div className="flex items-center">
              <AlertTriangle className="w-5 h-5 text-red-600 mr-2" />
              <div>
                <h4 className="font-medium text-red-800">Analysis Failed</h4>
                <p className="text-red-700 text-sm mt-1">{tensorFlowResult.error}</p>
              </div>
            </div>
          </div>
        )}
      </div>
    );
  };

  const renderDetectionHistory = () => {
    if (detectionHistory.length === 0) return null;

    return (
      <div className="mt-8 border border-purple-200 rounded-lg p-6 bg-purple-50">
        <h3 className="text-lg font-medium text-purple-900 mb-4 flex items-center">
          üìä Detection History
          <span className="ml-2 text-xs bg-purple-200 text-purple-800 px-2 py-1 rounded">
            Last {detectionHistory.length} detections
          </span>
        </h3>
        
        <div className="space-y-2">
          {detectionHistory.map((detection) => (
            <div key={detection.id} className="bg-white rounded-lg p-3 border border-purple-200">
              <div className="flex items-center justify-between">
                <div className="flex items-center space-x-3">
                  <span className="font-medium text-purple-900">{detection.species}</span>
                  <span className="text-purple-600 text-sm">
                    {(detection.confidence * 100).toFixed(1)}%
                  </span>
                </div>
                <span className="text-gray-500 text-xs">{detection.timestamp}</span>
              </div>
              {detection.conservationStatus && (
                <div className="mt-1">
                  <span className={`px-2 py-1 rounded text-xs ${
                    detection.conservationStatus.includes('Endangered') ? 'bg-red-100 text-red-800' :
                    detection.conservationStatus.includes('Vulnerable') ? 'bg-yellow-100 text-yellow-800' :
                    'bg-green-100 text-green-800'
                  }`}>
                    {detection.conservationStatus}
                  </span>
                </div>
              )}
            </div>
          ))}
        </div>
      </div>
    );
  };

  const renderCameraSection = () => (
    <div className="mt-8 border border-gray-200 rounded-lg p-6">
      <h3 className="text-lg font-medium text-gray-900 mb-4 flex items-center">
        <Camera className="w-5 h-5 mr-2" />
        Real-time Wildlife Monitoring
      </h3>
      
      <div className="space-y-4">
        <div className="flex space-x-4">
          {!stream ? (
            <button
              onClick={startCamera}
              disabled={!systemReady}
              className="bg-green-600 text-white px-4 py-2 rounded-lg hover:bg-green-700 disabled:opacity-50 disabled:cursor-not-allowed flex items-center"
            >
              <Camera className="w-4 h-4 mr-2" />
              {systemReady ? 'Start Camera' : 'System Loading...'}
            </button>
          ) : (
            <>
              <button
                onClick={stopCamera}
                className="bg-red-600 text-white px-4 py-2 rounded-lg hover:bg-red-700 flex items-center"
              >
                Stop Camera
              </button>
              <button
                onClick={() => setIsMonitoring(!isMonitoring)}
                className={`px-4 py-2 rounded-lg flex items-center ${
                  isMonitoring 
                    ? 'bg-yellow-600 text-white hover:bg-yellow-700' 
                    : 'bg-blue-600 text-white hover:bg-blue-700'
                }`}
              >
                <Zap className="w-4 h-4 mr-2" />
                {isMonitoring ? 'Stop Monitoring' : 'Start Monitoring'}
              </button>
              <button
                onClick={captureAndAnalyze}
                disabled={!systemReady}
                className="bg-purple-600 text-white px-4 py-2 rounded-lg hover:bg-purple-700 disabled:opacity-50 flex items-center"
              >
                <Brain className="w-4 h-4 mr-2" />
                Analyze Frame
              </button>
              <button
                onClick={testVideoDisplay}
                className="bg-yellow-600 text-white px-4 py-2 rounded-lg hover:bg-yellow-700 flex items-center"
                title="Test video display functionality"
              >
                <span className="mr-2">üîç</span>
                Test Video
              </button>
            </>
          )}
        </div>
        
        {/* Video Feed - Always render but conditionally show */}
        <div className="relative bg-gray-100 rounded-lg p-4">
          <div className="text-center mb-2">
            <span className="text-sm font-medium text-gray-700">üìπ Live Camera Feed</span>
          </div>
          <video
            ref={videoRef}
            autoPlay
            muted
            playsInline
            className="w-full max-w-lg mx-auto rounded-lg border-2 border-blue-300 bg-black shadow-lg"
            style={{ 
              minHeight: '300px',
              maxHeight: '500px',
              objectFit: 'cover'
            }}
            onLoadedMetadata={() => {
              console.log("üìπ Video metadata loaded");
              // Force dimensions update
              const video = videoRef.current;
              if (video) {
                console.log(`üìê Video dimensions: ${video.videoWidth}x${video.videoHeight}`);
              }
            }}
          />
          {!stream && (
            <div className="flex items-center justify-center" style={{ minHeight: '300px' }}>
              <div className="text-center">
                <div className="text-gray-500 mb-4">
                  üì∑ Camera not started
                </div>
                <button
                  onClick={startCamera}
                  className="px-4 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600"
                >
                  Start Camera
                </button>
              </div>
            </div>
          )}
          <canvas ref={canvasRef} className="hidden" />
          
          {stream && (
            <>
              {isMonitoring && (
                <div className="absolute top-6 right-6 bg-red-600 text-white px-3 py-1 rounded-full text-xs font-medium animate-pulse shadow-lg">
                  üî¥ LIVE MONITORING
                </div>
              )}
              
              {/* Enhanced debug info */}
              <div className="absolute bottom-2 left-2 bg-black bg-opacity-75 text-white text-xs p-3 rounded-lg">
                <div className="space-y-1">
                  <div>Stream: {stream ? '‚úÖ Active' : '‚ùå Inactive'}</div>
                  <div>System: {systemReady ? '‚úÖ Ready' : '‚è≥ Loading'}</div>
                  <div>Monitoring: {isMonitoring ? 'üî¥ Active' : '‚ö™ Stopped'}</div>
                  <div>Video: {videoRef.current?.readyState >= 2 ? '‚úÖ Playing' : '‚è≥ Loading'}</div>
                  <div>Dimensions: {videoRef.current ? `${videoRef.current.videoWidth || 0}x${videoRef.current.videoHeight || 0}` : 'N/A'}</div>
                </div>
              </div>
            </>
          )}
        </div>
      </div>
    </div>
  );

  return (
    <div className="max-w-4xl mx-auto p-6">
      <div className="text-center mb-8">
        <h1 className="text-3xl font-bold text-gray-900 mb-2 flex items-center justify-center">
          <Globe className="w-8 h-8 mr-3 text-green-600" />
          Enterprise Wildlife Detection System
        </h1>
        <p className="text-gray-600">
          State-of-the-art AI powered by 6 pre-trained models with 89.3% - 97.8% accuracy
        </p>
      </div>

      {renderSystemStatus()}

      <div className="border-2 border-dashed border-gray-300 rounded-lg p-8 text-center hover:border-gray-400 transition-colors">
        <input
          type="file"
          ref={fileInputRef}
          onChange={handleFileSelect}
          accept="image/*"
          className="hidden"
        />
        
        {previewUrl ? (
          <div className="space-y-4">
            <img 
              src={previewUrl} 
              alt="Preview" 
              className="max-w-full h-64 object-contain mx-auto rounded-lg border border-gray-200"
            />
            <div className="flex justify-center space-x-4">
              <button
                onClick={() => fileInputRef.current?.click()}
                className="bg-blue-600 text-white px-4 py-2 rounded-lg hover:bg-blue-700 flex items-center"
              >
                <UploadIcon className="w-4 h-4 mr-2" />
                Choose Different Image
              </button>
              <button
                onClick={handleUpload}
                disabled={!selectedFile}
                className="bg-green-600 text-white px-4 py-2 rounded-lg hover:bg-green-700 disabled:opacity-50 disabled:cursor-not-allowed flex items-center"
              >
                <Check className="w-4 h-4 mr-2" />
                Upload to Server
              </button>
            </div>
          </div>
        ) : (
          <div 
            onClick={() => fileInputRef.current?.click()}
            className="cursor-pointer"
          >
            <UploadIcon className="w-12 h-12 text-gray-400 mx-auto mb-4" />
            <p className="text-lg font-medium text-gray-700 mb-2">Upload Wildlife Image</p>
            <p className="text-gray-500">Click to select an image or drag and drop</p>
          </div>
        )}
      </div>

      {renderTensorFlowResults()}
      {renderCameraSection()}
      {renderDetectionHistory()}
    </div>
  );
};

export default Upload;